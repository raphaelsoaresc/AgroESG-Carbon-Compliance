# üåø AgroESG Carbon Compliance

> **Status:** ‚úÖ Orquestra√ß√£o (Cosmos) Ativa | üß† Motor de Compliance Operacional | üöß Visualiza√ß√£o (Front-end) em Breve

Este projeto √© uma solu√ß√£o de **Analytics Engineering & Data Engineering** focada na valida√ß√£o de crit√©rios ESG para origina√ß√£o de cr√©ditos de carbono. A arquitetura evoluiu de um pipeline de extra√ß√£o simples para um ecossistema robusto que traduz o **C√≥digo Florestal Brasileiro** em regras de dados audit√°veis.

## üèó Arquitetura e Stack

O projeto utiliza uma abordagem **Medallion Architecture** (Bronze, Silver, Gold) orquestrada por um ambiente imut√°vel.

    graph TD
        subgraph "Ingest√£o (Bronze)"
            A[Fontes: SIGEF & IBAMA] -->|DuckDB Spatial| B[Parquet Files / GCS]
        end

        subgraph "Orquestra√ß√£o Din√¢mica (Astronomer Cosmos)"
            B --> C{Airflow DAG}
            C -->|Renderiza| D[dbt Core Models]
        end

        subgraph "Transforma√ß√£o & Intelig√™ncia (Silver/Gold)"
            D --> E[Limpeza & Padroniza√ß√£o]
            E --> F[Geospatial Joins (BigQuery Geo)]
            F --> G[Regras de Neg√≥cio: Marco Temporal & Biomas]
            G --> H[C√°lculo de Risco por Contamina√ß√£o]
        end

        H --> I[Tabela Final: Compliance Risk]

---

# üöÄ Diferenciais de Engenharia

### 1. Ingest√£o de Alta Performance (DuckDB + Parquet)
Em vez de carregar dados brutos diretamente no Data Warehouse, o pipeline utiliza o **DuckDB** com a extens√£o `spatial` para realizar o *pre-processing* local. Ele converte Shapefiles e CSVs massivos em arquivos **Parquet** altamente compactados e tipados. Isso reduz o volume de dados trafegados para o Cloud Storage e acelera drasticamente a carga no BigQuery.

### 2. Ambiente Herm√©tico (Nix & uv)
O projeto utiliza **Nix** para gerenciar depend√™ncias a n√≠vel de sistema operacional (como as bibliotecas C++ do **GDAL/GEOS**). Combinado com o **uv**, isso garante um ambiente 100% reprodut√≠vel, eliminando o cl√°ssico "funciona na minha m√°quina".

### 3. Estrat√©gia ELT Geoespacial (Push-down Computation)
O pipeline delega o processamento de geometrias pesadas para o **BigQuery**. O dbt materializa as transforma√ß√µes dentro do Data Warehouse, permitindo escalar de milhares para milh√µes de pol√≠gonos sem estourar mem√≥ria RAM, aproveitando a computa√ß√£o distribu√≠da da nuvem.

### 4. Defensive Coding em SQL
Implementa√ß√£o de tratamentos robustos para geometrias inv√°lidas via `SAFE.ST_GEOGFROMTEXT` e filtros de `SAFE_DIVIDE`. Isso impede que uma √∫nica geometria corrompida no SIGEF/IBAMA derrube o pipeline inteiro, garantindo resili√™ncia operacional.

### 5. Orquestra√ß√£o At√¥mica (Cosmos)
A integra√ß√£o via **Astronomer Cosmos** permite que cada modelo dbt seja tratado como uma tarefa individual no Airflow. Isso oferece observabilidade granular: se o c√°lculo de risco falhar, o Airflow permite reexecutar apenas aquela parte (**retries parciais**), sem reprocessar a ingest√£o bruta.

---

# üß† L√≥gica de Compliance (Geospatial Intelligence)

O cora√ß√£o do projeto reside nas regras de neg√≥cio codificadas em SQL via **dbt**:

*   **Classifica√ß√£o de Biomas (IBGE):** Cruzamento espacial para determinar se a propriedade incide na Amaz√¥nia Legal, Cerrado ou Mata Atl√¢ntica.
*   **Veredito do Marco Temporal:** Bloqueio total para infra√ß√µes p√≥s-2008 na Amaz√¥nia e monitoramento para infra√ß√µes anteriores.
*   **Risco por Contamina√ß√£o (Adjacency Risk):** Identifica√ß√£o de pol√≠gonos eleg√≠veis que tocam √°reas embargadas, prevenindo a "lavagem" de commodities irregulares.

---

# üß∞ Stack T√©cnica

*   **Ingest√£o:** DuckDB (Spatial Extension) + Python.
*   **Orquestra√ß√£o:** Apache Airflow 2.10 + Astronomer Cosmos.
*   **Transforma√ß√£o:** dbt Core (BigQuery Adapter).
*   **Data Lakehouse:** Google BigQuery & Cloud Storage (Parquet format).
*   **Ambiente:** Gerenciado via `devenv` (Nix) para isolamento total.

---

# üöÄ Como Executar o Projeto

### 1. Prepare o Ambiente
```bash
devenv shell
devenv up -d  # Inicia servi√ßos locais
```

### 2. Inicialize o Airflow
```bash
start-airflow
```

### 3. Documenta√ß√£o e Linhagem
```bash
dbt docs generate && dbt docs serve
```

---

# üó∫ Roadmap Atualizado

* [x] **Infraestrutura:** Ambiente Nix com Postgres e Airflow configurados.
* [x] **Ingest√£o SIGEF:** Pipeline DuckDB convertendo dados brutos para Parquet e enviando ao GCS.
* [x] **Ingest√£o IBAMA:** Carga resiliente de Shapefiles via DuckDB Spatial.
* [x] **Camada Silver (dbt):** Modelos de limpeza e deduplica√ß√£o l√≥gica (*Last Record Wins*).
* [x] **Camada Gold (dbt):** Implementa√ß√£o do Spatial Join e regras de Marco Temporal.
* [ ] **Front-end:** Interface visual para exibir o mapa de risco (Streamlit).
* [ ] **API:** Expor os resultados de compliance via REST API.

---
**Autor:** Raphael Soares