# üåø AgroESG Carbon Compliance

> **Status:** ‚úÖ Orquestra√ß√£o (Cosmos) Ativa | üß† Motor de Compliance Operacional | üöß Visualiza√ß√£o (Front-end) em Breve

Este projeto √© uma solu√ß√£o de **Analytics Engineering & Data Engineering** focada na valida√ß√£o de crit√©rios ESG para origina√ß√£o de cr√©ditos de carbono. A arquitetura evoluiu de um pipeline de extra√ß√£o simples para um ecossistema robusto que traduz o **C√≥digo Florestal Brasileiro** em regras de dados audit√°veis.

## üéØ O Problema de Neg√≥cio

Para garantir a integridade de cr√©ditos de carbono, √© necess√°rio auditar:
1.  **Sobreposi√ß√£o com Embargos:** A propriedade invade √°reas embargadas pelo IBAMA?
2.  **Marco Temporal:** A infra√ß√£o ocorreu antes ou depois de julho de 2008?
3.  **Regras de Bioma:** A propriedade respeita a reserva legal espec√≠fica do bioma (ex: 80% na Amaz√¥nia)?
4.  **Risco de Contamina√ß√£o:** A propriedade √© vizinha imediata de uma √°rea desmatada?

## üèó Arquitetura e Fluxo de Dados

O projeto utiliza a **Medallion Architecture** (Bronze, Silver, Gold) para garantir a qualidade do dado:

*   **1. Camada Bronze (Ingest√£o):** Extra√ß√£o das fontes SIGEF e IBAMA via **DuckDB Spatial**, convertendo dados brutos para **Parquet** e armazenando no Google Cloud Storage.
*   **2. Orquestra√ß√£o (Airflow + Cosmos):** O **Astronomer Cosmos** mapeia o projeto dbt e gera as tarefas no Airflow automaticamente, garantindo a linhagem.
*   **3. Camada Silver (Transforma√ß√£o):** Limpeza, padroniza√ß√£o e deduplica√ß√£o l√≥gica (*Last Record Wins*) via **dbt**.
*   **4. Camada Gold (Intelig√™ncia):** Processamento geoespacial no **BigQuery** para Joins espaciais, aplica√ß√£o do Marco Temporal e c√°lculo de risco de contamina√ß√£o.

---

# üöÄ Diferenciais de Engenharia

### 1. Ingest√£o de Alta Performance (DuckDB + Parquet)
O pipeline utiliza o **DuckDB** com a extens√£o `spatial` para realizar o *pre-processing* local. Ele converte Shapefiles e CSVs massivos em arquivos **Parquet** compactados. Isso reduz o volume de dados trafegados e acelera a carga no Data Warehouse.

### 2. Ambiente Herm√©tico (Nix & uv)
O projeto utiliza **Nix** para gerenciar depend√™ncias a n√≠vel de sistema operacional (como as bibliotecas C++ do **GDAL/GEOS**). Combinado com o **uv**, isso garante um ambiente 100% reprodut√≠vel e imut√°vel, eliminando o erro "funciona na minha m√°quina".

### 3. Estrat√©gia ELT Geoespacial (Push-down Computation)
Em vez de processar geometrias pesadas em Python, o pipeline delega o processamento para o **BigQuery**. O dbt materializa as transforma√ß√µes dentro do Data Warehouse, permitindo escalar para milh√µes de pol√≠gonos aproveitando a computa√ß√£o distribu√≠da.

### 4. Defensive Coding em SQL
Implementa√ß√£o de tratamentos robustos para geometrias inv√°lidas via `SAFE.ST_GEOGFROMTEXT` e filtros de `SAFE_DIVIDE`. Isso impede que uma √∫nica geometria corrompida derrube o pipeline inteiro, garantindo resili√™ncia operacional.

### 5. Orquestra√ß√£o At√¥mica (Cosmos)
A integra√ß√£o via **Astronomer Cosmos** permite que cada modelo dbt seja uma tarefa individual no Airflow. Isso oferece observabilidade granular: se o c√°lculo de risco falhar, o Airflow permite reexecutar apenas aquela parte (**retries parciais**).

---

# üß† L√≥gica de Compliance (Geospatial Intelligence)

*   **Classifica√ß√£o de Biomas (IBGE):** Cruzamento espacial para determinar incid√™ncia na Amaz√¥nia Legal, Cerrado ou Pantanal.
*   **Veredito do Marco Temporal:** Bloqueio total para infra√ß√µes p√≥s-2008 na Amaz√¥nia e monitoramento para infra√ß√µes anteriores.
*   **Risco por Contamina√ß√£o (Adjacency Risk):** Identifica√ß√£o de pol√≠gonos que tocam √°reas embargadas, prevenindo a "lavagem" de commodities irregulares.

---

# üß∞ Stack T√©cnica

*   **Ingest√£o:** DuckDB (Spatial Extension) + Python.
*   **Orquestra√ß√£o:** Apache Airflow 2.10 + Astronomer Cosmos.
*   **Transforma√ß√£o:** dbt Core (BigQuery Adapter).
*   **Data Lakehouse:** Google BigQuery & Cloud Storage.
*   **Ambiente:** Gerenciado via `devenv` (Nix) e `uv`.

---

# üöÄ Como Executar o Projeto

### 1. Prepare o Ambiente
```bash
devenv shell
devenv up -d  # Inicia servi√ßos locais
```

### 2. Inicialize o Airflow
```bash
start-airflow
```

### 3. Documenta√ß√£o e Linhagem
```bash
dbt docs generate && dbt docs serve
```

---

# üó∫ Roadmap Atualizado

* [x] **Infraestrutura:** Ambiente Nix com Postgres e Airflow configurados via `devenv`.
* [x] **Camada Bronze (Ingest√£o):** Pipelines DuckDB convertendo dados brutos para Parquet e enviando ao GCS.
* [x] **Camada Silver (dbt):** Modelos de limpeza e deduplica√ß√£o l√≥gica.
* [x] **Camada Gold (dbt):** Implementa√ß√£o do Spatial Join e regras de Marco Temporal.
* [ ] **Front-end:** Interface visual para exibir o mapa de risco (Streamlit).
* [ ] **API:** Expor os resultados de compliance via REST API.

---
**Autor:** Raphael Soares

*Projeto desenvolvido para portf√≥lio de Data Engineering & Analytics.*