# üåø AgroESG Carbon Compliance

> **Status:** üöÄ Infraestrutura Operacional | üöß Refatora√ß√£o (Migra√ß√£o de Scripts `src/` para Airflow)

Este projeto √© uma solu√ß√£o de **Engenharia de Dados (ELT)** focada em an√°lise de risco e compliance ambiental para a origina√ß√£o de cr√©ditos de carbono. O objetivo √© cruzar dados geoespaciais de propriedades rurais com listas de embargos ambientais (IBAMA) e malhas fundi√°rias (SIGEF), garantindo a elegibilidade ESG atrav√©s de uma arquitetura resiliente.

## üéØ O Problema de Neg√≥cio

Para emitir cr√©ditos de carbono de alta integridade, √© necess√°rio garantir que a √°rea do projeto n√£o possui sobreposi√ß√£o com √°reas embargadas. Por√©m, fontes governamentais s√£o inst√°veis, mudam formatos sem aviso e bloqueiam requisi√ß√µes automatizadas. Este projeto cria um **"Bunker de Dados"** para garantir a ingest√£o cont√≠nua, mesmo em cen√°rios hostis.

## üèó Arquitetura e Stack

O projeto segue uma abordagem **H√≠brida (Local Stealth + Cloud Performance)**, utilizando Nix para infraestrutura imut√°vel.

* **Ingest√£o Resiliente (Airflow + Tor):** Extra√ß√£o an√¥nima via rede Tor para evitar bloqueios de IP e *fingerprinting* TLS (`curl_cffi`).
* **Pr√©-processamento (DuckDB):** Convers√£o local de CSVs gigantes para Parquet com tipagem forte e verifica√ß√£o de Hash (Idempot√™ncia).
* **Data Warehouse (Google BigQuery):** Armazenamento escal√°vel dos dados brutos e tratados.
* **Transforma√ß√£o (dbt Core):** Modelagem de dados e regras de neg√≥cio executadas diretamente no BigQuery.
* **Gerenciamento de Ambiente:** `devenv` (Nix) para orquestrar servi√ßos (Tor, Postgres, Airflow) sem sujar o sistema operacional.

## ‚öôÔ∏è Funcionalidades Implementadas (Scripts `src/`)

A l√≥gica atual reside em scripts Python robustos (`src/`) que est√£o sendo migrados para DAGs do Airflow:

1.  **Extra√ß√£o "Anti-Bloqueio" (IBAMA):**
    *   Simula√ß√£o de navegador real (Chrome) para bypass de firewall.
    *   **Fallback Autom√°tico:** Se o site oficial cair, o sistema busca o backup mais recente no Google Cloud Storage para n√£o quebrar o dashboard.
    *   **Zero Desperd√≠cio:** Valida√ß√£o de ETag/Hash MD5 antes do processamento. Se o dado n√£o mudou, o pipeline para.

2.  **Tratamento Geoespacial (SIGEF):**
    *   Leitura de Shapefiles complexos e convers√£o para WKT (Well-Known Text).
    *   Padroniza√ß√£o de tipagem para garantir integridade na camada Raw do BigQuery.

## üöÄ Como Executar o Projeto

Este projeto utiliza **Nix** e **Devenv**. N√£o √© necess√°rio instalar Python, GDAL ou Banco de Dados manualmente.

### Pr√©-requisitos
* Instalar [Nix](https://nixos.org/download.html)
* Instalar [Devenv](https://devenv.sh/getting-started/)

### Passo a Passo

1.  **Inicie a Infraestrutura (Tor + Postgres):**
    ```bash
    devenv up
    ```
    *Isso iniciar√° o Proxy Tor (porta 9050) e o PostgreSQL em segundo plano.*

2.  **Entre no shell de desenvolvimento:**
    ```bash
    devenv shell
    ```
    *Na primeira execu√ß√£o, o Airflow ser√° instalado e configurado automaticamente.*

3.  **Inicie o Orquestrador:**
    ```bash
    start-airflow
    ```
    *Acesse `localhost:8080` com a senha gerada no terminal.*

4.  **Valide a Conex√£o H√≠brida:**
    ```bash
    check-connection
    ```
    *Deve retornar um IP do Tor (Ingest√£o) e seu IP Real (Upload).*

## üó∫ Roadmap (Refatora√ß√£o & Analytics)

O foco atual √© portar a intelig√™ncia dos scripts Python isolados para a estrutura gerenci√°vel do Airflow:

* [x] **Infraestrutura:** Ambiente Nix com Tor, Airflow e DuckDB configurados.
* [ ] **Refatora√ß√£o (Ingest√£o):** Converter `src/extract_load_ibama.py` para DAG do Airflow.
* [ ] **Refatora√ß√£o (Geo):** Converter `src/load_sigef_raw.py` para DAG do Airflow.
* [ ] **Data Warehouse:** Configurar tabelas Raw no BigQuery.
* [ ] **Transforma√ß√£o (dbt):** Criar modelos `stg` (limpeza) e `marts` (regras de compliance).

---
**Autor:** Raphael Soares
*Projeto desenvolvido para portf√≥lio de Data Engineering & Analytics.*